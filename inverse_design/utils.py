# AUTOGENERATED! DO NOT EDIT! File to edit: notebooks/01_utils.ipynb (unless otherwise specified).

__all__ = ['conv', 'conv2d', 'batch_conv2d', 'dilute', 'randn', 'rand', 'argmax2d', 'argmin2d', 'float_mask', 'not_',
           'or_', 'and_', 'xor_', 'where_']

# Internal Cell
from functools import wraps

import jax
import jax.numpy as jnp
import numpy as np
from jax import lax

# Cell
def conv(lhs, rhs, window_strides=(1,1), padding="SAME", **kwargs):
    if not lhs.dtype == rhs.dtype:
        raise ValueError(f"Cannot do convolution. Different dtypes for 'lhs' and 'rhs'. Got: {lhs.dtype}, {rhs.dtype}")
    elif lhs.dtype in (jnp.float16, jnp.float32, jnp.float64):
        return lax.conv(lhs, rhs, window_strides, padding, **kwargs)
    else:
        raise ValueError(f"Cannot do convolution. Unsupported dtype: {lhs.dtype}.")

# Cell
@wraps(conv)
def conv2d(lhs, rhs, window_strides=(1,1), padding="SAME", **kwargs):
    return conv(lhs[None, None, :, :], rhs[None, None, :, :], window_strides, padding, **kwargs)[0, 0, :, :]

# Cell
@wraps(conv)
def batch_conv2d(lhs, rhs, window_strides=(1,1), padding="SAME", **kwargs):
    return conv(lhs[:, None, :, :], rhs[:, None, :, :], window_strides, padding, **kwargs)[:, 0, :, :]

# Cell
def dilute(touches, brush):
    result = conv2d(
        lhs=touches,
        rhs=brush,
        window_strides=(1, 1),
        padding="SAME",
    )
    return jnp.where(result > 1e-10, 1.0, 0.0)

# Cell
def randn(shape, r=None, dtype=float):
    if r is not None:
        if isinstance(r, int):
            r = np.random.RandomState(seed=r)
    else:
        r = np.random
    return jnp.asarray(r.randn(*shape), dtype=dtype)

# Cell
def rand(shape, r=None, dtype=float):
    if r is not None:
        if isinstance(r, int):
            r = np.random.RandomState(seed=r)
    else:
        r = np.random
    return jnp.asarray(r.rand(*shape), dtype=dtype)

# Cell
@jax.jit
def argmax2d(arr2d):
    m, n = arr2d.shape
    arr1d = arr2d.ravel()
    k = jnp.argmax(arr1d)
    return k//m, k%m

# Cell
@jax.jit
def argmin2d(arr2d):
    m, n = arr2d.shape
    arr1d = arr2d.ravel()
    k = jnp.argmin(arr1d)
    return k//m, k%m

# Cell
@jax.jit
def float_mask(boolean_mask):
    assert boolean_mask.dtype == bool
    return jnp.asarray(jnp.where(boolean_mask, 1.0, 0.0), dtype=jnp.float32)

# Cell
@jax.jit
def not_(lhs):
    return 1.0 - lhs

# Cell
@jax.jit
def or_(lhs, rhs):
    result = lhs + rhs
    return jnp.asarray(jnp.where(result > 1, 1.0, result), dtype=float)

# Cell
@jax.jit
def and_(lhs, rhs):
    return lhs * rhs

# Cell
@jax.jit
def xor_(lhs, rhs):
    return (lhs + rhs)%2.0

# Cell
@jax.jit
def where_(float_mask, x, y):
    return jnp.where(float_mask > 0.5, x, y)